# 量化的继续学习

> [PyTorch模型量化工具学习 - 知乎 (zhihu.com)](https://zhuanlan.zhihu.com/p/144025236)
>
> [后训练量化 · 语雀 (yuque.com)](https://www.yuque.com/yahei/hey-yahei/quantization-post_training)

- bias一般是不进行量化操作的，仍然保持float32的数据类型，还有一个需要提前说明的
- weight在浮点模型训练收敛之后一般就已经固定住了，所以根据原始数据就可以直接量化，
- activation会因为每次输入数据的不同，导致数据范围每次都是不同的，所以针对这个问题，在量化过程中专门会有一个校准过程，即提前准备一个小的校准数据集，在测试这个校准数据集的时候会记录每一次的activation的数据范围，然后根据记录值确定一个固定的范围。

## 1、pytorch自带工具量化流程

> 流程可以用来参考

### 1.1 准备模型

准备一个收敛了的浮点模型，用 QuantStub 和 DeQuantstub 模块指定需要量化的位置

### 1.2 模块融合

将一些相邻模块进行融合来提高计算效率，比如 conv + relu 、conv + bn + relu，

### 1.3 确定量化方案

这一步确定量化的后端（qnnpack/fbgemm/None，这块不清楚），量化的方法（per-layer/per-channel，对称/非对称），activation校准的策略（最大最小/移动平均/L2Norm）

### 1.4 activation 校准

利用 torch.quantization.prepare() 插入将在校准期间观察激活张量的模块，然后将校准数据集灌入模型，利用校准策略得到每层activation的scale和zero_point并存储；

### 1.5 模块转换

使用 torch.quantization.convert() 函数对整个模型进行量化的转换。这其中包括：量化权重，计算并存储要在每个激活张量中使用的scale和zero_point，替换关键运算符的量化实现；

