{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "accessible-actress",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from a_basic_quant.ipynb\n",
      "importing Jupyter notebook from b_model.ipynb\n",
      "importing Jupyter notebook from c_train_and_test.ipynb\n",
      "importing Jupyter notebook from d_post_training_quantize.ipynb\n"
     ]
    }
   ],
   "source": [
    "import Ipynb_importer\n",
    "from a_basic_quant import *\n",
    "from b_model import *\n",
    "from c_train_and_test import *\n",
    "from d_post_training_quantize import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "constitutional-update",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "descending-executive",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 1, 28, 28])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.randn((64,1,28,28))\n",
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "coordinated-brook",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv = torch.nn.Conv2d(1, 40, 3, 1)\n",
    "res = conv(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "white-publicity",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 40, 26, 26])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "elect-solution",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2.372403621673584,\n",
       " 2.511977434158325,\n",
       " 1.831723928451538,\n",
       " 2.1057021617889404,\n",
       " 2.2107653617858887]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_val =[float(res[:,i,:,:].max() )for i in range(len(res[0]))] \n",
    "max_val[:5]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "federal-insulation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-2.066378355026245,\n",
       " -2.436711311340332,\n",
       " -2.116239547729492,\n",
       " -1.4519824981689453,\n",
       " -2.306870698928833]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_val = [float(res[:,i,:,:].min() )for i in range(len(res[0]))] \n",
    "min_val[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dramatic-optimization",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[118.0, 125.0, 136.0, 104.0, 130.0]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scale = []\n",
    "zero_point = []\n",
    "for i in range(len(max_val)):\n",
    "    s, z = calcu_scale_and_zeropoint(min_val[i], max_val[i], 8)\n",
    "    scale.append(s)\n",
    "    zero_point.append(z)\n",
    "    \n",
    "scale[:5]\n",
    "zero_point[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "wired-bearing",
   "metadata": {},
   "outputs": [],
   "source": [
    "def quantize_tensor(x:list, scale:list, zero_point:list, num_bits=8):\n",
    "    q_min = 0.\n",
    "    q_max = 2. ** num_bits -1.\n",
    "    \n",
    "    q_x = torch.zeros(x.shape)\n",
    "    for i in range(len(scale)):\n",
    "        q_x[:,i,:,:] = x[:,i,:,:] /scale[i] + zero_point[i]\n",
    "        q_x[:,i,:,:].clamp_(0, 255).round()\n",
    "        \n",
    "    return q_x.int()\n",
    "\n",
    "def dequantize_tensor(q_x, scale, zero_point):\n",
    "    x = torch.zeros(q_x.shape)\n",
    "    for i in range(len(scale)):\n",
    "        x[:,i,:,:] = scale[i] * (q_x[:,i,:,:] - zero_point[i])\n",
    "    \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "lightweight-musical",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([122, 135, 110, 122, 112], dtype=torch.int32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_res = quantize_tensor(res, scale, zero_point)\n",
    "q_res[0][0][0][0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "agricultural-breach",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.0696,  0.2959, -0.1393,  0.0696, -0.1044, -0.9574, -0.1915,  0.1741,\n",
       "         0.7311,  0.6789,  0.7659,  0.4004,  0.6789, -0.9052, -0.8355, -0.2089,\n",
       "         0.2785,  0.4700, -0.5918,  0.0174,  0.1567,  0.2611, -0.1044,  0.2611,\n",
       "         0.0522, -0.0696])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dq_res = dequantize_tensor(q_res, scale, zero_point)\n",
    "dq_res[0][0:5][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "adapted-memphis",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.0818,  0.3110, -0.1340,  0.0779, -0.0960, -0.9421, -0.1799,  0.1898,\n",
       "         0.7397,  0.6930,  0.7696,  0.4015,  0.6838, -0.9022, -0.8329, -0.1941,\n",
       "         0.2952,  0.4715, -0.5874,  0.0283,  0.1636,  0.2781, -0.0994,  0.2707,\n",
       "         0.0542, -0.0564], grad_fn=<SelectBackward>)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res[0][0:5][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "photographic-venue",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9921568627450981"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scale = lambda max_val, min_val :  float((max_val - min_val) / (255))\n",
    "s = scale(255,2)\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "sharp-bradley",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "238"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calcu_zero_point = lambda max_val, min_val :  np.clip(int(255 - max_val / s), 0,255)\n",
    "z = calcu_zero_point(16,2)\n",
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "verbal-compound",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "67"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calcu_scale =  lambda max_val, min_val : float((max_val - min_val) / (q_max - q_min))\n",
    "calcu_zero_point = lambda max_val, scale :  np.clip(int(q_max - max_val / scale), q_min, q_max)\n",
    "\n",
    "q_max = 255\n",
    "q_min = 0\n",
    "scale = calcu_scale(64,-23)\n",
    "scale\n",
    "zero_point = calcu_zero_point(64, scale)\n",
    "zero_point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "occasional-glossary",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcu_scale_and_zeropoint(min_val, max_val, num_bits=8, is_per_channel_quantize=False):\n",
    "    # 计算 scale 和 zero_point 的基本公式\n",
    "    # is_per_channel_quantize 决定是按照逐通道量化还是按照逐层量化来计算 scale 和 zero_point \n",
    "    q_min = 0.\n",
    "    q_max = 2. ** num_bits - 1\n",
    "    \n",
    "    # 匿名函数，计算 scale 和 zero_point\n",
    "    calcu_scale =  lambda max_val, min_val : float((max_val - min_val) / (q_max - q_min))\n",
    "    calcu_zero_point = lambda max_val, scale :  np.clip(int(q_max - max_val / scale), q_min, q_max)\n",
    "    \n",
    "    # 是否是逐通道量化\n",
    "    if  is_per_channel_quantize:\n",
    "        scale = []\n",
    "        zero_point = []\n",
    "\n",
    "        for i in range(len(min_val)):\n",
    "            scale.append(calcu_scale(max_val[i], min_val[i]))\n",
    "            zero_point.append( calcu_zero_point(max_val[i], scale[i]))  \n",
    "            \n",
    "    else:\n",
    "        scale = calcu_scale(max_val, min_val)\n",
    "        zero_point = calcu_zero_point(max_val, scale)\n",
    "        \n",
    "    return scale, zero_point\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "vietnamese-gambling",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3411764705882353 67.0\n"
     ]
    }
   ],
   "source": [
    "scale, zero_point = calcu_scale_and_zeropoint(-23, 64)\n",
    "print(scale, zero_point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "hydraulic-cloud",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.017406988143920898, 0.019406622531367282, 0.015482209710513844, 0.013951704548854454, 0.017716219845940084, 0.025020348791982613, 0.018590784072875975, 0.021531027438593846, 0.015164483762254903, 0.018993748870550418, 0.01880497651941636, 0.021872305402568744, 0.016954759522980336, 0.016447824590346393, 0.016811740164663278, 0.022289041444367053, 0.012003157185573203, 0.019158273584702436, 0.01622291873483097, 0.0213474245632396, 0.01177502192702948, 0.015453707470613368, 0.013611221780963972, 0.011446661107680377, 0.020656879275452858, 0.01838410321403952, 0.019261037602144128, 0.01818844570833094, 0.02404925028483073, 0.015078667098400639, 0.022204766553990982, 0.018716723311181162, 0.02474205540675743, 0.01698904504962996, 0.015915822982788087, 0.018676993426154642, 0.022611205718096564, 0.01764062245686849, 0.016676984113805433, 0.023288680057899625] [118.0, 125.0, 136.0, 104.0, 130.0, 120.0, 143.0, 115.0, 147.0, 134.0, 144.0, 156.0, 116.0, 124.0, 109.0, 126.0, 153.0, 140.0, 122.0, 127.0, 105.0, 126.0, 147.0, 130.0, 120.0, 138.0, 131.0, 109.0, 126.0, 138.0, 117.0, 112.0, 129.0, 131.0, 135.0, 119.0, 135.0, 105.0, 130.0, 130.0]\n"
     ]
    }
   ],
   "source": [
    "scale, zero_point = calcu_scale_and_zeropoint(min_val, max_val, 8, True)\n",
    "print(scale, zero_point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "latest-upgrade",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def quantize_tensor(x, scale, zero_point, num_bits=8, is_per_channel_quantize=False ):\n",
    "    # 计算 scale 和 zero_point 的基本公式\n",
    "    # is_per_channel_quantize 决定是按照逐通道量化还是按照逐层量化\n",
    "    q_min = 0.\n",
    "    q_max = 2. ** num_bits - 1\n",
    "    \n",
    "    if is_per_channel_quantize:\n",
    "        q_x = torch.zeros(x.shape)\n",
    "        for i in range(len(scale)):\n",
    "            q_x[:,i,:,:] = x[:,i,:,:] /scale[i] + zero_point[i]\n",
    "            q_x[:,i,:,:].clamp_(0, 255).round()\n",
    "            \n",
    "    else:\n",
    "        q_x = x / scale + zero_point\n",
    "        q_x.clamp_(q_min, q_max).round()  # q=round(r/S+Z)\n",
    "        \n",
    "    return q_x.int()\n",
    "\n",
    "def dequantize_tensor(q_x, scale, zero_point, is_per_channel_quantize=False ):\n",
    "    \n",
    "    if is_per_channel_quantize:\n",
    "        \n",
    "        x = torch.zeros(q_x.shape)\n",
    "        for i in range(len(scale)):\n",
    "            x[:,i,:,:] = scale[i] * (q_x[:,i,:,:] - zero_point[i])\n",
    "            \n",
    "    else:\n",
    "        x = scale * (q_x -zero_point)\n",
    "        \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "changed-comment",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([122, 135, 110, 122, 112], dtype=torch.int32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_res = quantize_tensor(res, scale, zero_point, 8, True)\n",
    "q_res[0][0][0][0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "immediate-moment",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.0696,  0.2959, -0.1393,  0.0696, -0.1044, -0.9574, -0.1915,  0.1741,\n",
       "         0.7311,  0.6789,  0.7659,  0.4004,  0.6789, -0.9052, -0.8355, -0.2089,\n",
       "         0.2785,  0.4700, -0.5918,  0.0174,  0.1567,  0.2611, -0.1044,  0.2611,\n",
       "         0.0522, -0.0696])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dq_res = dequantize_tensor(q_res, scale, zero_point, True)\n",
    "dq_res[0][0:5][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "arctic-sweden",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.0818,  0.3110, -0.1340,  0.0779, -0.0960, -0.9421, -0.1799,  0.1898,\n",
       "         0.7397,  0.6930,  0.7696,  0.4015,  0.6838, -0.9022, -0.8329, -0.1941,\n",
       "         0.2952,  0.4715, -0.5874,  0.0283,  0.1636,  0.2781, -0.0994,  0.2707,\n",
       "         0.0542, -0.0564], grad_fn=<SelectBackward>)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res[0][0:5][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "assumed-columbus",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_layer = res.max()\n",
    "min_layer = res.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "third-tackle",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.026581289246678352 128.0\n"
     ]
    }
   ],
   "source": [
    "scale_layer, zero_point_layer = calcu_scale_and_zeropoint(min_layer, max_layer, 8, False)\n",
    "print(scale_layer, zero_point_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "clinical-mandate",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([131, 139, 122, 130, 124], dtype=torch.int32)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_res_layer = quantize_tensor(res, scale_layer, zero_point_layer, 8, False)\n",
    "q_res_layer[0][0][0][0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "psychological-variation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.0797,  0.2924, -0.1595,  0.0532, -0.1063, -0.9569, -0.1861,  0.1861,\n",
       "         0.7177,  0.6911,  0.7443,  0.3987,  0.6645, -0.9038, -0.8506, -0.2127,\n",
       "         0.2924,  0.4519, -0.6114,  0.0266,  0.1595,  0.2658, -0.1063,  0.2658,\n",
       "         0.0532, -0.0797])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dq_res_layer = dequantize_tensor(q_res_layer, scale_layer, zero_point_layer, False)\n",
    "dq_res_layer[0][0:5][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "congressional-intermediate",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcu_max_and_min(x, max_val, min_val, is_per_channel_quantize=False ):\n",
    "    calcu_max = lambda x, max_val: max(0, x.max()) if max_val is None \\\n",
    "                                                                else max(0, x.max(), max_val)\n",
    "    calcu_min = lambda x, min_val: min(0, x.min()) if min_val is None \\\n",
    "                                                                else min(0, x.min(), min_val)\n",
    "    if is_per_channel_quantize:\n",
    "#         max_val =[calcu_max(x[:,i,:,:], max_val[i]) for i in range(len(x[0]))]    \n",
    "#         min_val =[calcu_min(x[:,i,:,:], min_val[i]) for i in range(len(x[0]))]    这样写也行，不过读起来差一点\n",
    "        new_max_val = []\n",
    "        new_min_val = []\n",
    "        for i in range(len(x[0])):\n",
    "            if max_val == None or  max_val[i] == None:\n",
    "                new_max_val.append(calcu_max(x[:,i,:,:], None))\n",
    "            else:\n",
    "                new_max_val.append(calcu_max(x[:,i,:,:], max_val[i]))\n",
    "            if min_val == None or  min_val[i] == None:\n",
    "                new_min_val.append(calcu_min(x[:,i,:,:], None))\n",
    "            else:\n",
    "                new_min_val.append(calcu_min(x[:,i,:,:], min_val[i]))\n",
    "            \n",
    "    else:\n",
    "        new_max_val = calcu_max(x, max_val)\n",
    "        new_min_val = calcu_min(x, min_val)\n",
    "        \n",
    "    return new_min_val, new_max_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "south-plumbing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-3.4151, grad_fn=<MinBackward1>) tensor(3.3631, grad_fn=<MaxBackward1>)\n"
     ]
    }
   ],
   "source": [
    "min_layer, max_layer = calcu_max_and_min(res, None, None, False)\n",
    "print(min_layer, max_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "artistic-wrestling",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor(-2.0664, grad_fn=<MinBackward1>), tensor(-2.4367, grad_fn=<MinBackward1>), tensor(-2.1162, grad_fn=<MinBackward1>), tensor(-1.4520, grad_fn=<MinBackward1>), tensor(-2.3069, grad_fn=<MinBackward1>), tensor(-3.0171, grad_fn=<MinBackward1>), tensor(-2.6649, grad_fn=<MinBackward1>), tensor(-2.4907, grad_fn=<MinBackward1>), tensor(-2.2375, grad_fn=<MinBackward1>), tensor(-2.5613, grad_fn=<MinBackward1>), tensor(-2.7123, grad_fn=<MinBackward1>), tensor(-3.4151, grad_fn=<MinBackward1>), tensor(-1.9707, grad_fn=<MinBackward1>), tensor(-2.0458, grad_fn=<MinBackward1>), tensor(-1.8461, grad_fn=<MinBackward1>), tensor(-2.8166, grad_fn=<MinBackward1>), tensor(-1.8463, grad_fn=<MinBackward1>), tensor(-2.6948, grad_fn=<MinBackward1>), tensor(-1.9904, grad_fn=<MinBackward1>), tensor(-2.7237, grad_fn=<MinBackward1>), tensor(-1.2434, grad_fn=<MinBackward1>), tensor(-1.9492, grad_fn=<MinBackward1>), tensor(-2.0022, grad_fn=<MinBackward1>), tensor(-1.4950, grad_fn=<MinBackward1>), tensor(-2.4877, grad_fn=<MinBackward1>), tensor(-2.5485, grad_fn=<MinBackward1>), tensor(-2.5408, grad_fn=<MinBackward1>), tensor(-1.9924, grad_fn=<MinBackward1>), tensor(-3.0464, grad_fn=<MinBackward1>), tensor(-2.0941, grad_fn=<MinBackward1>), tensor(-2.6043, grad_fn=<MinBackward1>), tensor(-2.1091, grad_fn=<MinBackward1>), tensor(-3.1933, grad_fn=<MinBackward1>), tensor(-2.2392, grad_fn=<MinBackward1>), tensor(-2.1617, grad_fn=<MinBackward1>), tensor(-2.2322, grad_fn=<MinBackward1>), tensor(-3.0551, grad_fn=<MinBackward1>), tensor(-1.8533, grad_fn=<MinBackward1>), tensor(-2.1716, grad_fn=<MinBackward1>), tensor(-3.0500, grad_fn=<MinBackward1>)] [tensor(2.3724, grad_fn=<MaxBackward1>), tensor(2.5120, grad_fn=<MaxBackward1>), tensor(1.8317, grad_fn=<MaxBackward1>), tensor(2.1057, grad_fn=<MaxBackward1>), tensor(2.2108, grad_fn=<MaxBackward1>), tensor(3.3631, grad_fn=<MaxBackward1>), tensor(2.0758, grad_fn=<MaxBackward1>), tensor(2.9997, grad_fn=<MaxBackward1>), tensor(1.6295, grad_fn=<MaxBackward1>), tensor(2.2821, grad_fn=<MaxBackward1>), tensor(2.0830, grad_fn=<MaxBackward1>), tensor(2.1623, grad_fn=<MaxBackward1>), tensor(2.3528, grad_fn=<MaxBackward1>), tensor(2.1484, grad_fn=<MaxBackward1>), tensor(2.4409, grad_fn=<MaxBackward1>), tensor(2.8671, grad_fn=<MaxBackward1>), tensor(1.2145, grad_fn=<MaxBackward1>), tensor(2.1905, grad_fn=<MaxBackward1>), tensor(2.1464, grad_fn=<MaxBackward1>), tensor(2.7199, grad_fn=<MaxBackward1>), tensor(1.7592, grad_fn=<MaxBackward1>), tensor(1.9915, grad_fn=<MaxBackward1>), tensor(1.4686, grad_fn=<MaxBackward1>), tensor(1.4239, grad_fn=<MaxBackward1>), tensor(2.7798, grad_fn=<MaxBackward1>), tensor(2.1395, grad_fn=<MaxBackward1>), tensor(2.3708, grad_fn=<MaxBackward1>), tensor(2.6456, grad_fn=<MaxBackward1>), tensor(3.0862, grad_fn=<MaxBackward1>), tensor(1.7510, grad_fn=<MaxBackward1>), tensor(3.0579, grad_fn=<MaxBackward1>), tensor(2.6637, grad_fn=<MaxBackward1>), tensor(3.1159, grad_fn=<MaxBackward1>), tensor(2.0930, grad_fn=<MaxBackward1>), tensor(1.8968, grad_fn=<MaxBackward1>), tensor(2.5304, grad_fn=<MaxBackward1>), tensor(2.7108, grad_fn=<MaxBackward1>), tensor(2.6451, grad_fn=<MaxBackward1>), tensor(2.0810, grad_fn=<MaxBackward1>), tensor(2.8886, grad_fn=<MaxBackward1>)]\n"
     ]
    }
   ],
   "source": [
    "min_channel, max_channel = calcu_max_and_min(res, None, None, True)\n",
    "print(min_channel, max_channel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "sealed-charles",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.01740698702633381, 0.019406622275710106, 0.015482209622859955, 0.01395170483738184, 0.017716221511363983, 0.02502034790813923, 0.018590785562992096, 0.02153102681040764, 0.015164483338594437, 0.018993748351931572, 0.01880497671663761, 0.021872306242585182, 0.016954759135842323, 0.016447825357317924, 0.016811741515994072, 0.022289041429758072, 0.012003157287836075, 0.019158273935317993, 0.016222918406128883, 0.021347424015402794, 0.011775022372603416, 0.015453707426786423, 0.013611221686005592, 0.011446661315858364, 0.020656879991292953, 0.01838410273194313, 0.019261037930846214, 0.018188446760177612, 0.024049250409007072, 0.015078667551279068, 0.022204766049981117, 0.0187167227268219, 0.02474205568432808, 0.016989046707749367, 0.015915822237730026, 0.018676992505788803, 0.022611206397414207, 0.017640622332692146, 0.01667698472738266, 0.023288680240511894] [118.0, 125.0, 136.0, 104.0, 130.0, 120.0, 143.0, 115.0, 147.0, 134.0, 144.0, 156.0, 116.0, 124.0, 109.0, 126.0, 153.0, 140.0, 122.0, 127.0, 105.0, 126.0, 147.0, 130.0, 120.0, 138.0, 131.0, 109.0, 126.0, 138.0, 117.0, 112.0, 129.0, 131.0, 135.0, 119.0, 135.0, 105.0, 130.0, 130.0]\n"
     ]
    }
   ],
   "source": [
    "scale_channel, zero_point_channel = calcu_scale_and_zeropoint(min_channel, max_channel, 8, True)\n",
    "print(scale_channel, zero_point_channel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "single-disposal",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([122, 135, 110, 122, 112], dtype=torch.int32)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_res_channel = quantize_tensor(res, scale_channel, zero_point_channel, 8, True)\n",
    "q_res_channel[0][0][0][0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "optical-aquatic",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.0696,  0.2959, -0.1393,  0.0696, -0.1044, -0.9574, -0.1915,  0.1741,\n",
       "         0.7311,  0.6789,  0.7659,  0.4004,  0.6789, -0.9052, -0.8355, -0.2089,\n",
       "         0.2785,  0.4700, -0.5918,  0.0174,  0.1567,  0.2611, -0.1044,  0.2611,\n",
       "         0.0522, -0.0696])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dq_res_channel = dequantize_tensor(q_res_channel, scale_channel, zero_point_channel,True)\n",
    "dq_res_channel[0][0:5][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "immediate-quantity",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.0818,  0.3110, -0.1340,  0.0779, -0.0960, -0.9421, -0.1799,  0.1898,\n",
       "         0.7397,  0.6930,  0.7696,  0.4015,  0.6838, -0.9022, -0.8329, -0.1941,\n",
       "         0.2952,  0.4715, -0.5874,  0.0283,  0.1636,  0.2781, -0.0994,  0.2707,\n",
       "         0.0542, -0.0564], grad_fn=<SelectBackward>)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res[0][0:5][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "assured-integration",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "japanese-algeria",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
