{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fluid-exhaust",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from a_basic_quant.ipynb\n",
      "importing Jupyter notebook from b_model.ipynb\n",
      "importing Jupyter notebook from c_train_and_test.ipynb\n",
      "importing Jupyter notebook from d_post_training_quantize.ipynb\n"
     ]
    }
   ],
   "source": [
    "import Ipynb_importer\n",
    "from a_basic_quant import *\n",
    "from b_model import *\n",
    "from c_train_and_test import *\n",
    "from d_post_training_quantize import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "superb-sacramento",
   "metadata": {},
   "source": [
    "## 1、深入理解卷积中量化的细节"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efficient-provision",
   "metadata": {},
   "source": [
    "### 1.1 定义一个输入并且输出指定范围数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "essential-annual",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.4792, 0.6436, 1.5960, 0.5424, 0.9110])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.randn((64,1,28,28))\n",
    "a[0][0][0][:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "numeric-treasure",
   "metadata": {},
   "source": [
    "### 1.2 定义一个卷积"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "younger-removal",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv = torch.nn.Conv2d(1, 40, 3, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unlimited-drunk",
   "metadata": {},
   "source": [
    "### 1.3 进行卷积运算并且输出指定范围数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "backed-growing",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.7314,  0.8412,  1.1721,  0.4059, -0.0070], grad_fn=<SliceBackward>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = conv(a)\n",
    "res[0][0][0][:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "incorporated-pitch",
   "metadata": {},
   "source": [
    "> 上面一步的目的是模拟正常运算，此时网络中的权重和偏置已存在"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "breathing-three",
   "metadata": {},
   "source": [
    "### 1.4 进行对输入的量化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "recognized-bronze",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "原始： tensor([0.4792, 0.6436, 1.5960, 0.5424, 0.9110])\n",
      "量化： tensor([146, 151, 181, 148, 159], dtype=torch.int32)\n",
      "反量化： tensor([0.4745, 0.6327, 1.5817, 0.5378, 0.8857])\n"
     ]
    }
   ],
   "source": [
    "# 1\n",
    "min_a, max_a = calcu_max_and_min(a, None, None, False)\n",
    "# 2\n",
    "scale_a, zero_point_a = calcu_scale_and_zeropoint(min_a, max_a, 8, False)\n",
    "# 3\n",
    "q_a = quantize_tensor(a, scale_a, zero_point_a).int()\n",
    "# 4\n",
    "dq_a = dequantize_tensor(q_a, scale_a, zero_point_a)\n",
    "\n",
    "print(\"原始：\", a[0][0][0][:5])\n",
    "print(\"量化：\", q_a[0][0][0][:5])\n",
    "print(\"反量化：\", dq_a[0][0][0][:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "structured-assumption",
   "metadata": {},
   "source": [
    "### 1.5 进行对权重的量化\n",
    "两种量化方式，逐层量化、逐通道量化\n",
    "#### 1、逐通道量化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "informational-aging",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "原始： tensor([0.3315, 0.0992, 0.3202])\n",
      "量化： tensor([254, 156, 249], dtype=torch.int32)\n",
      "反量化： tensor([0.3297, 0.0989, 0.3179])\n"
     ]
    }
   ],
   "source": [
    "# 1、获取权重\n",
    "w = conv.weight.data\n",
    "# 2、\n",
    "min_w, max_w = calcu_max_and_min(w, None, None, True)\n",
    "# 3、\n",
    "scale_w, zero_point_w = calcu_scale_and_zeropoint(min_w, max_w, 8, True)\n",
    "# 4、\n",
    "q_w = quantize_tensor(w, scale_w, zero_point_w,8,False, True).int()\n",
    "# 5、\n",
    "dq_w = dequantize_tensor(q_w, scale_w, zero_point_w, True)\n",
    "\n",
    "print(\"原始：\", w[0][0][0][:5])\n",
    "print(\"量化：\", q_w[0][0][0][:5])\n",
    "print(\"反量化：\", dq_w[0][0][0][:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "searching-supervisor",
   "metadata": {},
   "source": [
    "#### 2、逐层量化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "effective-fashion",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "governing-spouse",
   "metadata": {},
   "source": [
    "> 省略对bias的量化"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "arbitrary-chemistry",
   "metadata": {},
   "source": [
    "### 1.6 进行对输出的量化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "federal-ethernet",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "原始： tensor([ 0.7314,  0.8412,  1.1721,  0.4059, -0.0070], grad_fn=<SliceBackward>)\n",
      "量化： tensor([155, 159, 171, 143, 127], dtype=torch.int32)\n",
      "反量化： tensor([ 0.7257,  0.8332,  1.1557,  0.4031, -0.0269])\n"
     ]
    }
   ],
   "source": [
    "# 1\n",
    "min_res, max_res = calcu_max_and_min(res, None, None, False)\n",
    "# 2\n",
    "scale_res, zero_point_res = calcu_scale_and_zeropoint(min_res, max_res, 8, False)\n",
    "# 3\n",
    "q_res = quantize_tensor(res, scale_res, zero_point_res).int()\n",
    "# 4\n",
    "dq_res = dequantize_tensor(q_res, scale_res, zero_point_res)\n",
    "\n",
    "print(\"原始：\", res[0][0][0][:5])\n",
    "print(\"量化：\", q_res[0][0][0][:5])\n",
    "print(\"反量化：\", dq_res[0][0][0][:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "antique-printer",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([40, 1, 3, 3])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_w.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "acknowledged-english",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(117., dtype=torch.float64)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor(zero_point_w)[23]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "electoral-wonder",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(zero_point_w)):\n",
    "    conv.weight.data[i] = q_w[i] - zero_point_w[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "abandoned-border",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 40, 26, 26])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_2 = q_a - zero_point_a\n",
    "y_2 = conv(x_2)\n",
    "y_2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "guided-nurse",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M = [scale_w[i] * scale_a / scale_res for i in range(len(scale_w))]\n",
    "len(M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "convertible-threshold",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-16.5199,  36.1009,  -6.6106,  -8.5260,   5.2803, -38.1270, -22.8699,\n",
       "        -11.2940,   8.4803, -14.0009,   1.4630, -28.0986,   8.9416,  -0.3656,\n",
       "         34.0861, -11.2549,  26.3759,  -8.0280,  16.1838, -22.1394,  20.9141,\n",
       "         18.2061, -43.3648,   8.4468,  24.7519,  -2.5970],\n",
       "       grad_fn=<SelectBackward>)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range(len(M)):\n",
    "    y_2[:,i,:,:] = y_2[:,i,:,:] * M[i]\n",
    "y_2[0][0:5][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "decimal-huntington",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([114.4801, 167.1010, 124.3894, 122.4740, 136.2803,  92.8730, 108.1301,\n",
       "        119.7060, 139.4803, 116.9991, 132.4630, 102.9014, 139.9416, 130.6344,\n",
       "        165.0862, 119.7451, 157.3759, 122.9720, 147.1837, 108.8606, 151.9141,\n",
       "        149.2061,  87.6352, 139.4468, 155.7519, 128.4030],\n",
       "       grad_fn=<SelectBackward>)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z_2 = y_2 +zero_point_res\n",
    "z_2[0][0:5][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "patient-darwin",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.4203,  0.9186, -0.1682, -0.2169,  0.1344, -0.9701, -0.5819, -0.2874,\n",
       "         0.2158, -0.3562,  0.0372, -0.7150,  0.2275, -0.0093,  0.8673, -0.2864,\n",
       "         0.6711, -0.2043,  0.4118, -0.5633,  0.5321,  0.4632, -1.1034,  0.2149,\n",
       "         0.6298, -0.0661], grad_fn=<SelectBackward>)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dz_2 = dequantize_tensor(z_2, scale_res, zero_point_res)\n",
    "dz_2[0][0:5][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "premium-reservoir",
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "interracial-meter",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ambient-philadelphia",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bulgarian-sociology",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "thick-humanity",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "geographic-magnet",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 1, 28, 28])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.randn((64,1,28,28))\n",
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "focused-newport",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv = torch.nn.Conv2d(1, 40, 3, 1)\n",
    "b = conv(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "registered-nickel",
   "metadata": {},
   "outputs": [],
   "source": [
    "qconv = QConv2d(conv, True, True, 8, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "functioning-registrar",
   "metadata": {},
   "outputs": [],
   "source": [
    "q_b = qconv(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "amino-farming",
   "metadata": {},
   "outputs": [],
   "source": [
    "qconv.freeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "sensitive-florist",
   "metadata": {},
   "outputs": [],
   "source": [
    "q_x = qconv.q_in.quantize_tensor(a)\n",
    "q_x = qconv.quantize_inference(q_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "blocked-bundle",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.5812, -0.7556, -0.3778,  0.0581, -0.1744,  0.6103,  0.2906,  0.4940,\n",
       "         0.0581, -0.1453, -0.1453,  0.3487,  1.0462,  0.1453, -0.4940, -0.4650,\n",
       "         0.1453, -0.1453, -0.7265, -0.0291,  0.6394,  0.9590,  0.6684,  0.1453,\n",
       "         0.1453,  1.0172], grad_fn=<SelectBackward>)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = qconv.q_out.dequantize_tensor(q_x)\n",
    "out[0][0][:5][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "satellite-tucson",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.5767, -0.7625, -0.3758,  0.0535, -0.1850,  0.6198,  0.2780,  0.4998,\n",
       "         0.0678, -0.1520, -0.1324,  0.3410,  1.0518,  0.1388, -0.4951, -0.4791,\n",
       "         0.1440, -0.1452, -0.7232, -0.0254,  0.6318,  0.9714,  0.6540,  0.1549,\n",
       "         0.1344,  1.0298], grad_fn=<SelectBackward>)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b[0][0][:5][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "violent-toyota",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "loose-table",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fitted-bidder",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "varied-moses",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-1.4769, device='cuda:0')"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.randn((64,1,28,28)).cuda()\n",
    "a[0][0][0][0]-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "adopted-berlin",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv = torch.nn.Conv2d(1, 40, 3, 1)\n",
    "conv.cuda()\n",
    "b = conv(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "periodic-assets",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "QConv2d(\n",
       "  (conv_module): Conv2d(1, 40, kernel_size=(3, 3), stride=(1, 1))\n",
       ")"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qconv = QConv2d(conv, True, True, 8, True)\n",
    "qconv.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "choice-acrylic",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Input type (torch.cuda.FloatTensor) and weight type (torch.FloatTensor) should be the same",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-41-626bde0345a6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mq_b\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mqconv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/envs/20210222_TensorRT官方开源库/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/1_code/15_quantize/quantize/1_uniform_prelayer_quantization - 副本/a_basic_quant.ipynb\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Input type (torch.cuda.FloatTensor) and weight type (torch.FloatTensor) should be the same"
     ]
    }
   ],
   "source": [
    "q_b = qconv(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "behavioral-attendance",
   "metadata": {},
   "outputs": [],
   "source": [
    "qconv.freeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "individual-banana",
   "metadata": {},
   "outputs": [],
   "source": [
    "q_x = qconv.q_in.quantize_tensor(a)\n",
    "q_x = qconv.quantize_inference(q_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "miniature-delhi",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = qconv.q_out.dequantize_tensor(q_x)\n",
    "out[0][0][:5][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "separated-motivation",
   "metadata": {},
   "outputs": [],
   "source": [
    "b[0][0][:5][0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
