{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "unauthorized-coaching",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from a_basic_quant.ipynb\n",
      "importing Jupyter notebook from b_model.ipynb\n",
      "importing Jupyter notebook from c_train_and_test.ipynb\n",
      "importing Jupyter notebook from d_post_training_quantize.ipynb\n"
     ]
    }
   ],
   "source": [
    "import Ipynb_importer\n",
    "from a_basic_quant import *\n",
    "from b_model import *\n",
    "from c_train_and_test import *\n",
    "from d_post_training_quantize import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "royal-billion",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 1, 28, 28])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.randn((64,1,28,28))\n",
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "general-enterprise",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv = torch.nn.Conv2d(1, 40, 3, 1)\n",
    "res = conv(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "adjusted-hunter",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-1.6115e+00,  2.5057e+00, -2.4694e-03,  6.5107e-01, -6.8049e-01,\n",
      "         1.5487e-01, -2.9745e-01,  1.8995e+00,  1.5417e+00,  8.7582e-01,\n",
      "         3.0330e-01,  1.0632e+00,  5.2285e-01, -1.2756e-01, -1.0106e+00,\n",
      "        -4.3086e-01,  2.0793e-01,  1.3761e+00, -4.0121e-01,  9.5955e-01,\n",
      "        -1.8500e+00,  1.0811e+00, -1.2179e+00,  9.6849e-01,  2.8365e-01,\n",
      "        -2.5091e-01,  1.5151e+00, -1.1316e+00])\n",
      "tensor([-1.6330,  2.4995, -0.0333,  0.6332, -0.6999,  0.1333, -0.2999,  1.8663,\n",
      "         1.5330,  0.8665,  0.2999,  1.0331,  0.4999, -0.1333, -1.0331, -0.4332,\n",
      "         0.2000,  1.3664, -0.4332,  0.9331, -1.8663,  1.0664, -1.2331,  0.9665,\n",
      "         0.2666, -0.2666,  1.4997, -1.1331])\n"
     ]
    }
   ],
   "source": [
    "min_a, max_a = calcu_max_and_min(a, None, None, False)\n",
    "scale_a, zero_point_a = calcu_scale_and_zeropoint(min_a, max_a, 8, False)\n",
    "q_a = quantize_tensor(a, scale_a, zero_point_a).int()\n",
    "dq_a = dequantize_tensor(q_a, scale_a, zero_point_a)\n",
    "print(a[0][0:5][0][0])\n",
    "print(dq_a[0][0:5][0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "moving-english",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.1926, 0.0502, 0.1333])\n",
      "tensor([0.1926, 0.0502, 0.1333])\n"
     ]
    }
   ],
   "source": [
    "w = conv.weight.data\n",
    "min_w, max_w = calcu_max_and_min(w, None, None, True)\n",
    "scale_w, zero_point_w = calcu_scale_and_zeropoint(min_w, max_w, 8, True)\n",
    "q_w = quantize_tensor(w, scale_w, zero_point_w,8,False, True)\n",
    "dq_w = dequantize_tensor(q_w, scale_w, zero_point_w, True)\n",
    "print(w[0][0:5][0][0])\n",
    "print(dq_w[0][0:5][0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "informative-methodology",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.1765,  0.8441, -0.7927,  0.0257, -1.1507,  0.8137,  0.6025,  0.8553,\n",
      "         1.0318,  0.0679,  0.2848,  0.0923, -0.3824, -0.3483,  0.0204,  0.6378,\n",
      "         0.6959,  0.0553, -0.9178, -0.6067, -0.9119, -0.0210, -0.4007, -0.1225,\n",
      "         0.1902,  0.4652], grad_fn=<SelectBackward>)\n",
      "tensor([-0.2036,  0.8435, -0.8144,  0.0000, -1.1634,  0.7853,  0.5817,  0.8435,\n",
      "         1.0180,  0.0582,  0.2618,  0.0873, -0.4072, -0.3490,  0.0000,  0.6108,\n",
      "         0.6690,  0.0291, -0.9307, -0.6108, -0.9307, -0.0291, -0.4072, -0.1454,\n",
      "         0.1745,  0.4363])\n"
     ]
    }
   ],
   "source": [
    "min_res, max_res = calcu_max_and_min(res, None, None, False)\n",
    "scale_res, zero_point_res = calcu_scale_and_zeropoint(min_res, max_res, 8, False)\n",
    "q_res = quantize_tensor(res, scale_res, zero_point_res).int()\n",
    "dq_res = dequantize_tensor(q_res, scale_res, zero_point_res)\n",
    "print(res[0][0:5][0][0])\n",
    "print(dq_res[0][0:5][0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "graduate-advance",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 3, 3])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_w[0].view(1,1,3,3).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "simple-affair",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv.bias[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "recognized-bradford",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 1, 26, 26])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = q_a - zero_point_a\n",
    "y = F.conv2d(input = x, weight = q_w[0].view(1,1,3,3), bias=conv.bias[0].view(1),\\\n",
    "            stride=conv.stride,\n",
    "            padding=conv.padding,\n",
    "            dilation=conv.dilation,\n",
    "            groups=conv.groups)\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "grateful-atlantic",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([40, 1, 3, 3])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv.weight.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "featured-philosophy",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([40, 1, 3, 3])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_w.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "drawn-windows",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(179., dtype=torch.float64)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor(zero_point_w)[23]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "third-soundtrack",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(zero_point_w)):\n",
    "    conv.weight.data[i] = q_w[i] - zero_point_w[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fantastic-audit",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 40, 26, 26])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_2 = q_a - zero_point_a\n",
    "y_2 = conv(x_2)\n",
    "y_2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "tamil-processing",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M = [scale_w[i] * scale_a / scale_res for i in range(len(scale_w))]\n",
    "len(M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "formal-belgium",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-11.3463,  24.0449, -32.4485,  -4.1960, -44.3211,  22.9628,  15.7608,\n",
       "         24.2389,  30.6368,  -2.5505,   4.6794,  -2.1993, -18.5277, -17.1324,\n",
       "         -4.3382,  16.7879,  18.6787,  -3.4253, -36.9573, -26.2078, -36.6000,\n",
       "         -5.8291, -19.2183,  -9.5266,   1.4173,  11.0966],\n",
       "       grad_fn=<SelectBackward>)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range(len(M)):\n",
    "    y_2[:,i,:,:] = y_2[:,i,:,:] * M[i]\n",
    "y_2[0][0:5][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "blond-modern",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([111.6537, 147.0449,  90.5515, 118.8040,  78.6789, 145.9628, 138.7608,\n",
       "        147.2389, 153.6368, 120.4494, 127.6794, 120.8007, 104.4723, 105.8676,\n",
       "        118.6618, 139.7879, 141.6787, 119.5747,  86.0427,  96.7922,  86.4000,\n",
       "        117.1709, 103.7817, 113.4734, 124.4173, 134.0966],\n",
       "       grad_fn=<SelectBackward>)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z_2 = y_2 +zero_point_res\n",
    "z_2[0][0:5][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dental-treat",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.3300,  0.6994, -0.9438, -0.1220, -1.2891,  0.6679,  0.4584,  0.7050,\n",
       "         0.8911, -0.0742,  0.1361, -0.0640, -0.5389, -0.4983, -0.1262,  0.4883,\n",
       "         0.5433, -0.0996, -1.0749, -0.7623, -1.0645, -0.1695, -0.5590, -0.2771,\n",
       "         0.0412,  0.3227], grad_fn=<SelectBackward>)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dz_2 = dequantize_tensor(z_2, scale_res, zero_point_res)\n",
    "dz_2[0][0:5][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hollywood-given",
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "crucial-horror",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bronze-module",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ordered-wheel",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "younger-annex",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "accomplished-frame",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 1, 28, 28])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.randn((64,1,28,28))\n",
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "automatic-population",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv = torch.nn.Conv2d(1, 40, 3, 1)\n",
    "b = conv(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "external-albert",
   "metadata": {},
   "outputs": [],
   "source": [
    "qconv = QConv2d(conv, True, True, 8, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "irish-lemon",
   "metadata": {},
   "outputs": [],
   "source": [
    "q_b = qconv(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "improved-technique",
   "metadata": {},
   "outputs": [],
   "source": [
    "qconv.freeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "sustained-singing",
   "metadata": {},
   "outputs": [],
   "source": [
    "q_x = qconv.q_in.quantize_tensor(a)\n",
    "q_x = qconv.quantize_inference(q_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "adopted-barbados",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.0259,  0.4147,  0.0518,  0.0000, -0.0778,  0.0778,  0.0778, -0.1555,\n",
       "        -0.1555, -0.3110,  0.7776, -0.7257,  0.7257, -0.9072,  0.1037,  1.2182,\n",
       "         0.0000, -0.5702,  0.6221,  0.9849, -0.3110,  0.3110, -0.1555, -0.6480,\n",
       "         0.2074,  0.9072], grad_fn=<SelectBackward>)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = qconv.q_out.dequantize_tensor(q_x)\n",
    "out[0][0][:5][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "nuclear-victory",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.0120,  0.4176,  0.0365, -0.0124, -0.0794,  0.0783,  0.0720, -0.1731,\n",
       "        -0.1704, -0.3277,  0.7650, -0.7318,  0.7227, -0.9066,  0.1060,  1.2092,\n",
       "        -0.0069, -0.5866,  0.6306,  0.9811, -0.3208,  0.3115, -0.1566, -0.6419,\n",
       "         0.1979,  0.9120], grad_fn=<SelectBackward>)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b[0][0][:5][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "second-suspension",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
