{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "independent-imperial",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from a_basic_quant.ipynb\n",
      "importing Jupyter notebook from b_model.ipynb\n",
      "importing Jupyter notebook from c_train_and_test.ipynb\n",
      "importing Jupyter notebook from d_post_training_quantize.ipynb\n"
     ]
    }
   ],
   "source": [
    "import Ipynb_importer\n",
    "from a_basic_quant import *\n",
    "from b_model import *\n",
    "from c_train_and_test import *\n",
    "from d_post_training_quantize import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "encouraging-marketing",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 1, 28, 28])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.randn((64,1,28,28))\n",
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "viral-pickup",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv = torch.nn.Conv2d(1, 40, 3, 1)\n",
    "res = conv(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "protective-conflict",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.7126,  0.1340,  1.4468,  0.1608, -0.4743,  0.5212, -1.5438, -0.0798,\n",
      "         1.3271,  0.2168, -1.1680, -1.3196, -0.4271,  0.2910,  0.8130,  0.7308,\n",
      "        -1.0762,  0.5525, -0.2756, -0.4258,  0.0287, -0.8183, -1.3653, -1.5111,\n",
      "         1.0644,  1.3089, -0.4093, -0.2931])\n",
      "tensor([ 0.6831,  0.1242,  1.4283,  0.1552, -0.4968,  0.4968, -1.5525, -0.0931,\n",
      "         1.3041,  0.1863, -1.1799, -1.3351, -0.4347,  0.2794,  0.8073,  0.7141,\n",
      "        -1.0867,  0.5278, -0.2794, -0.4347,  0.0000, -0.8383, -1.3662, -1.5214,\n",
      "         1.0557,  1.3041, -0.4347, -0.3105])\n"
     ]
    }
   ],
   "source": [
    "min_a, max_a = calcu_max_and_min(a, None, None, False)\n",
    "scale_a, zero_point_a = calcu_scale_and_zeropoint(min_a, max_a, 8, False)\n",
    "q_a = quantize_tensor(a, scale_a, zero_point_a).int()\n",
    "dq_a = dequantize_tensor(q_a, scale_a, zero_point_a)\n",
    "print(a[0][0:5][0][0])\n",
    "print(dq_a[0][0:5][0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dirty-radiation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.0546,  0.2338, -0.3169])\n",
      "tensor([ 0.0546,  0.2338, -0.3148])\n"
     ]
    }
   ],
   "source": [
    "w = conv.weight.data\n",
    "min_w, max_w = calcu_max_and_min(w, None, None, True)\n",
    "scale_w, zero_point_w = calcu_scale_and_zeropoint(min_w, max_w, 8, True)\n",
    "q_w = quantize_tensor(w, scale_w, zero_point_w,8,False, True)\n",
    "dq_w = dequantize_tensor(q_w, scale_w, zero_point_w, True)\n",
    "print(w[0][0:5][0][0])\n",
    "print(dq_w[0][0:5][0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "coordinate-stretch",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.2963,  1.0422, -0.0454, -0.0931,  0.2671, -0.8507, -0.4561, -0.1652,\n",
      "         0.3485, -0.2223,  0.1644, -0.5918,  0.3604,  0.1135,  0.9989, -0.1687,\n",
      "         0.8062, -0.0770,  0.5284, -0.4346,  0.6680,  0.5878, -0.9849,  0.3461,\n",
      "         0.7483,  0.0630], grad_fn=<SelectBackward>)\n",
      "tensor([-0.3053,  1.0178, -0.0509, -0.1018,  0.2544, -0.8651, -0.4580, -0.1781,\n",
      "         0.3308, -0.2290,  0.1527, -0.6107,  0.3562,  0.1018,  0.9923, -0.1781,\n",
      "         0.7888, -0.1018,  0.5089, -0.4580,  0.6616,  0.5852, -0.9923,  0.3308,\n",
      "         0.7379,  0.0509])\n"
     ]
    }
   ],
   "source": [
    "min_res, max_res = calcu_max_and_min(res, None, None, False)\n",
    "scale_res, zero_point_res = calcu_scale_and_zeropoint(min_res, max_res, 8, False)\n",
    "q_res = quantize_tensor(res, scale_res, zero_point_res).int()\n",
    "dq_res = dequantize_tensor(q_res, scale_res, zero_point_res)\n",
    "print(res[0][0:5][0][0])\n",
    "print(dq_res[0][0:5][0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "emerging-baghdad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 3, 3])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_w[0].view(1,1,3,3).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "informed-stake",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv.bias[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "several-lawrence",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 1, 26, 26])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = q_a - zero_point_a\n",
    "y = F.conv2d(input = x, weight = q_w[0].view(1,1,3,3), bias=conv.bias[0].view(1),\\\n",
    "            stride=conv.stride,\n",
    "            padding=conv.padding,\n",
    "            dilation=conv.dilation,\n",
    "            groups=conv.groups)\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "educational-radar",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([40, 1, 3, 3])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv.weight.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "suited-table",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([40, 1, 3, 3])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_w.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "refined-degree",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(117., dtype=torch.float64)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor(zero_point_w)[23]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ranging-transformation",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(zero_point_w)):\n",
    "    conv.weight.data[i] = q_w[i] - zero_point_w[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "swedish-mustang",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 40, 26, 26])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_2 = q_a - zero_point_a\n",
    "y_2 = conv(x_2)\n",
    "y_2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ordered-promotion",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M = [scale_w[i] * scale_a / scale_res for i in range(len(scale_w))]\n",
    "len(M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "systematic-irrigation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-16.5199,  36.1009,  -6.6106,  -8.5260,   5.2803, -38.1270, -22.8699,\n",
       "        -11.2940,   8.4803, -14.0009,   1.4630, -28.0986,   8.9416,  -0.3656,\n",
       "         34.0861, -11.2549,  26.3759,  -8.0280,  16.1838, -22.1394,  20.9141,\n",
       "         18.2061, -43.3648,   8.4468,  24.7519,  -2.5970],\n",
       "       grad_fn=<SelectBackward>)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range(len(M)):\n",
    "    y_2[:,i,:,:] = y_2[:,i,:,:] * M[i]\n",
    "y_2[0][0:5][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "direct-respect",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([114.4801, 167.1010, 124.3894, 122.4740, 136.2803,  92.8730, 108.1301,\n",
       "        119.7060, 139.4803, 116.9991, 132.4630, 102.9014, 139.9416, 130.6344,\n",
       "        165.0862, 119.7451, 157.3759, 122.9720, 147.1837, 108.8606, 151.9141,\n",
       "        149.2061,  87.6352, 139.4468, 155.7519, 128.4030],\n",
       "       grad_fn=<SelectBackward>)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z_2 = y_2 +zero_point_res\n",
    "z_2[0][0:5][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "working-administrator",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.4203,  0.9186, -0.1682, -0.2169,  0.1344, -0.9701, -0.5819, -0.2874,\n",
       "         0.2158, -0.3562,  0.0372, -0.7150,  0.2275, -0.0093,  0.8673, -0.2864,\n",
       "         0.6711, -0.2043,  0.4118, -0.5633,  0.5321,  0.4632, -1.1034,  0.2149,\n",
       "         0.6298, -0.0661], grad_fn=<SelectBackward>)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dz_2 = dequantize_tensor(z_2, scale_res, zero_point_res)\n",
    "dz_2[0][0:5][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "retained-touch",
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nearby-gateway",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "directed-machine",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "compound-interstate",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fixed-apparatus",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "divided-cologne",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 1, 28, 28])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.randn((64,1,28,28))\n",
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "demographic-peeing",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv = torch.nn.Conv2d(1, 40, 3, 1)\n",
    "b = conv(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "owned-trust",
   "metadata": {},
   "outputs": [],
   "source": [
    "qconv = QConv2d(conv, True, True, 8, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "rotary-pipeline",
   "metadata": {},
   "outputs": [],
   "source": [
    "q_b = qconv(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "furnished-syndicate",
   "metadata": {},
   "outputs": [],
   "source": [
    "qconv.freeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "intimate-methodology",
   "metadata": {},
   "outputs": [],
   "source": [
    "q_x = qconv.q_in.quantize_tensor(a)\n",
    "q_x = qconv.quantize_inference(q_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "allied-aruba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.5812, -0.7556, -0.3778,  0.0581, -0.1744,  0.6103,  0.2906,  0.4940,\n",
       "         0.0581, -0.1453, -0.1453,  0.3487,  1.0462,  0.1453, -0.4940, -0.4650,\n",
       "         0.1453, -0.1453, -0.7265, -0.0291,  0.6394,  0.9590,  0.6684,  0.1453,\n",
       "         0.1453,  1.0172], grad_fn=<SelectBackward>)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = qconv.q_out.dequantize_tensor(q_x)\n",
    "out[0][0][:5][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cordless-modern",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.5767, -0.7625, -0.3758,  0.0535, -0.1850,  0.6198,  0.2780,  0.4998,\n",
       "         0.0678, -0.1520, -0.1324,  0.3410,  1.0518,  0.1388, -0.4951, -0.4791,\n",
       "         0.1440, -0.1452, -0.7232, -0.0254,  0.6318,  0.9714,  0.6540,  0.1549,\n",
       "         0.1344,  1.0298], grad_fn=<SelectBackward>)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b[0][0][:5][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faced-influence",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "possible-disclaimer",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "constant-satellite",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "random-frame",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-1.4769, device='cuda:0')"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.randn((64,1,28,28)).cuda()\n",
    "a[0][0][0][0]-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "cultural-pontiac",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv = torch.nn.Conv2d(1, 40, 3, 1)\n",
    "conv.cuda()\n",
    "b = conv(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "fantastic-racing",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "QConv2d(\n",
       "  (conv_module): Conv2d(1, 40, kernel_size=(3, 3), stride=(1, 1))\n",
       ")"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qconv = QConv2d(conv, True, True, 8, True)\n",
    "qconv.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "catholic-portable",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Input type (torch.cuda.FloatTensor) and weight type (torch.FloatTensor) should be the same",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-41-626bde0345a6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mq_b\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mqconv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/envs/20210222_TensorRT官方开源库/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/1_code/15_quantize/quantize/1_uniform_prelayer_quantization - 副本/a_basic_quant.ipynb\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Input type (torch.cuda.FloatTensor) and weight type (torch.FloatTensor) should be the same"
     ]
    }
   ],
   "source": [
    "q_b = qconv(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "turned-infrastructure",
   "metadata": {},
   "outputs": [],
   "source": [
    "qconv.freeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "national-portfolio",
   "metadata": {},
   "outputs": [],
   "source": [
    "q_x = qconv.q_in.quantize_tensor(a)\n",
    "q_x = qconv.quantize_inference(q_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "excited-pledge",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = qconv.q_out.dequantize_tensor(q_x)\n",
    "out[0][0][:5][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dimensional-lucas",
   "metadata": {},
   "outputs": [],
   "source": [
    "b[0][0][:5][0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
