{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "applied-lying",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from a_basic_quant.ipynb\n",
      "importing Jupyter notebook from b_model.ipynb\n",
      "importing Jupyter notebook from c_train_and_test.ipynb\n",
      "importing Jupyter notebook from d_post_training_quantize.ipynb\n"
     ]
    }
   ],
   "source": [
    "import Ipynb_importer\n",
    "from a_basic_quant import *\n",
    "from b_model import *\n",
    "from c_train_and_test import *\n",
    "from d_post_training_quantize import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hazardous-puzzle",
   "metadata": {},
   "source": [
    "## 1、理解量化过程·教程\n",
    "### 1.1 获得一个输入 torch.tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "leading-remedy",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-90.1498,  -4.1381, -35.8254],\n",
       "        [102.5455, 132.4951, -70.6038]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn(2,3) *100\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "opponent-roman",
   "metadata": {},
   "source": [
    "### 1.2 获得 x 的最大值和最小值，确定上下限"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "negative-sucking",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_val: 132.49508666992188 \n",
      "min_val:-90.14982604980469\n"
     ]
    }
   ],
   "source": [
    "max_val = x.max()\n",
    "min_val = x.min()\n",
    "print(f\"max_val: {max_val} \\nmin_val:{min_val}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "robust-expression",
   "metadata": {},
   "source": [
    "### 1.3 计算缩放因子 scare, 零点 zero_point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "premier-guatemala",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scale: 0.8731173276901245 \n",
      "zero_point: 103.0\n"
     ]
    }
   ],
   "source": [
    "scale, zero_point = calcu_scale_and_zeropoint(min_val, max_val)\n",
    "print(f\"scale: {scale} \\nzero_point: {zero_point}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lasting-catch",
   "metadata": {},
   "source": [
    "### 1.4 进行量化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fitting-deposit",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  0.0000,  98.2606,  61.9684],\n",
       "        [220.4475, 254.7495,  22.1359]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_x = quantize_tensor(x, scale, zero_point)\n",
    "q_x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "incorrect-toolbox",
   "metadata": {},
   "source": [
    "### 1.5 反量化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "atomic-profession",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "原始值：\n",
      "tensor([[-90.1498,  -4.1381, -35.8254],\n",
      "        [102.5455, 132.4951, -70.6038]]) \n",
      "量化反量化：\n",
      "tensor([[-89.9311,  -4.1381, -35.8254],\n",
      "        [102.5455, 132.4951, -70.6038]])\n"
     ]
    }
   ],
   "source": [
    "x_q_x = dequantize_tensor(q_x, scale, zero_point)\n",
    "\n",
    "print(f\"原始值：\\n{x} \\n量化反量化：\\n{x_q_x}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "furnished-skill",
   "metadata": {},
   "source": [
    "## 2、深入理解卷积中量化的细节"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "academic-opportunity",
   "metadata": {},
   "source": [
    "### 2.1 定义一个输入并且输出指定范围数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "active-hometown",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 2.1448,  0.4215, -0.3201, -1.2773,  0.8699])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.randn((64,1,28,28))\n",
    "a[0][0][0][:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "spectacular-sample",
   "metadata": {},
   "source": [
    "### 2.2 定义一个卷积"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "manual-halloween",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv = torch.nn.Conv2d(1, 40, 3, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dental-retail",
   "metadata": {},
   "source": [
    "### 2.3 进行卷积运算并且输出指定范围数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dedicated-cardiff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.8252,  0.2801,  0.6957, -1.0605,  1.0631], grad_fn=<SliceBackward>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = conv(a)\n",
    "res[0][0][0][:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "corporate-polish",
   "metadata": {},
   "source": [
    "> 上面一步的目的是模拟正常运算，此时网络中的权重和偏置已存在"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "foreign-honey",
   "metadata": {},
   "source": [
    "### 2.4 量化\n",
    "#### 1、 进行对输入的量化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cross-scientist",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "原始： tensor([ 2.1448,  0.4215, -0.3201, -1.2773,  0.8699])\n",
      "量化： tensor([198, 145, 123,  93, 159], dtype=torch.int32)\n",
      "反量化： tensor([ 2.1136,  0.3902, -0.3252, -1.3007,  0.8455])\n"
     ]
    }
   ],
   "source": [
    "# 1\n",
    "min_a, max_a = calcu_max_and_min(a, None, None, False)\n",
    "# 2\n",
    "scale_a, zero_point_a = calcu_scale_and_zeropoint(min_a, max_a, 8, False)\n",
    "# 3\n",
    "q_a = quantize_tensor(a, scale_a, zero_point_a).int()\n",
    "# 4\n",
    "dq_a = dequantize_tensor(q_a, scale_a, zero_point_a)\n",
    "\n",
    "print(\"原始：\", a[0][0][0][:5])\n",
    "print(\"量化：\", q_a[0][0][0][:5])\n",
    "print(\"反量化：\", dq_a[0][0][0][:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "similar-approach",
   "metadata": {},
   "source": [
    "#### 2、 进行对权重的量化\n",
    "两种量化方式，逐层量化、逐通道量化\n",
    "\n",
    "这里展示的是逐通道量化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "phantom-tampa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "原始： tensor([ 0.1693, -0.3146,  0.0790])\n",
      "量化： tensor([200.0798,   0.0000, 162.6877])\n",
      "反量化： tensor([ 0.1693, -0.3140,  0.0790])\n"
     ]
    }
   ],
   "source": [
    "# 1、获取权重\n",
    "w = conv.weight.data\n",
    "# 2、\n",
    "min_w, max_w = calcu_max_and_min(w, None, None, True)\n",
    "# 3、\n",
    "scale_w, zero_point_w = calcu_scale_and_zeropoint(min_w, max_w, 8, True)\n",
    "# 4、\n",
    "q_w = quantize_tensor(w, scale_w, zero_point_w,8,False, True)\n",
    "# 5、\n",
    "dq_w = dequantize_tensor(q_w, scale_w, zero_point_w, True)\n",
    "\n",
    "print(\"原始：\", w[0][0][0][:5])\n",
    "print(\"量化：\", q_w[0][0][0][:5])\n",
    "print(\"反量化：\", dq_w[0][0][0][:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "painted-donna",
   "metadata": {},
   "source": [
    "#### 3、 进行对输出的量化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "joint-irrigation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "原始： tensor([ 0.8252,  0.2801,  0.6957, -1.0605,  1.0631], grad_fn=<SliceBackward>)\n",
      "量化： tensor([162, 139, 157,  83, 172], dtype=torch.int32)\n",
      "反量化： tensor([ 0.8155,  0.2638,  0.6955, -1.0793,  1.0553])\n"
     ]
    }
   ],
   "source": [
    "# 1\n",
    "min_res, max_res = calcu_max_and_min(res, None, None, False)\n",
    "# 2\n",
    "scale_res, zero_point_res = calcu_scale_and_zeropoint(min_res, max_res, 8, False)\n",
    "# 3\n",
    "q_res = quantize_tensor(res, scale_res, zero_point_res).int()\n",
    "# 4\n",
    "dq_res = dequantize_tensor(q_res, scale_res, zero_point_res)\n",
    "\n",
    "print(\"原始：\", res[0][0][0][:5])\n",
    "print(\"量化：\", q_res[0][0][0][:5])\n",
    "print(\"反量化：\", dq_res[0][0][0][:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "living-twins",
   "metadata": {},
   "source": [
    "### 2.5 卷积中权值更新为量化权值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "environmental-consumer",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv.weight.data = q_w"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exceptional-darwin",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 2.6 进行推理\n",
    "<img src=\"https://www.zhihu.com/equation?tex=S_a+%28q_a-Z_a%29%3D%5Csum_%7Bi%7D%5EN+S_w%28q_w-Z_w%29S_x%28q_x-Z_x%29%2BS_b%28q_b-Z_b%29+%5Ctag%7B2%7D+\" alt=\"[公式]\" style=\"zoom:80%;\" />\n",
    "<img src=\"https://www.zhihu.com/equation?tex=q_a%3D%5Cfrac%7BS_w+S_x%7D%7BS_a%7D%5Csum_%7Bi%7D%5EN+%28q_w-Z_w%29%28q_x-Z_x%29%2B%5Cfrac%7BS_b%7D%7BS_a%7D%28q_b-Z_b%29%2BZ_a+%5Ctag%7B3%7D+\" alt=\"[公式]\" style=\"zoom:80%;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pharmaceutical-storage",
   "metadata": {},
   "source": [
    "#### 1、量化输入"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fourth-oriental",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_1 = q_a - zero_point_a"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "elect-checklist",
   "metadata": {},
   "source": [
    "#### 2、进行卷积\n",
    "> 注意：\n",
    "> 1. 这里的输入已经模拟量化了\n",
    "> 2. 卷积中的权重在上面某步中被模拟量化了（偏置被忽略了）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "romantic-apache",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_2 = conv(x_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sought-clarity",
   "metadata": {},
   "source": [
    "#### 3、计算 M\n",
    "\n",
    "![[公式]](https://www.zhihu.com/equation?tex=M%3D%5Cfrac%7BS_1+S_2%7D%7BS_3%7D)\n",
    "\n",
    "注意：\n",
    "\n",
    "> 1. M的计算公式根据逐层量化和逐通道量化方式的不同而不同，这里展示的是逐通道量化的公式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "different-breach",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M = [scale_w[i] * scale_a / scale_res for i in range(len(scale_w))]\n",
    "len(M)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "olive-brush",
   "metadata": {},
   "source": [
    "#### 4、M 与 量化卷积乘积\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "worldwide-jewelry",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(M)):\n",
    "    y_2[:,i,:,:] = y_2[:,i,:,:] * M[i]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "linear-number",
   "metadata": {},
   "source": [
    "#### 5、加上 输出的zero_point\n",
    "这里得到的是量化的输出结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "congressional-professional",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([220.0485, 148.4445, 217.4412, 156.8067, 255.8525],\n",
       "       grad_fn=<SliceBackward>)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z_3 = y_2 +zero_point_res\n",
    "    \n",
    "z_3[0][0][0][:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bigger-temperature",
   "metadata": {},
   "source": [
    "#### 6、反量化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "damaged-korean",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2.2077, 0.4903, 2.1452, 0.6909, 3.0664], grad_fn=<SliceBackward>)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dz_4 = dequantize_tensor(z_3, scale_res, zero_point_res)\n",
    "dz_4[0][0][0][:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "demonstrated-enlargement",
   "metadata": {},
   "source": [
    "#### 7、与原始结果对比"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bridal-comfort",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "原始： tensor([ 0.8252,  0.2801,  0.6957, -1.0605,  1.0631], grad_fn=<SliceBackward>)\n",
      "量化： tensor([162, 139, 157,  83, 172], dtype=torch.int32)\n",
      "反量化： tensor([ 0.8155,  0.2638,  0.6955, -1.0793,  1.0553])\n"
     ]
    }
   ],
   "source": [
    "print(\"原始：\", res[0][0][0][:5])\n",
    "print(\"量化：\", q_res[0][0][0][:5])\n",
    "print(\"反量化：\", dq_res[0][0][0][:5]) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "superior-subcommittee",
   "metadata": {},
   "source": [
    "## 3、卷积中量化（封装）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stopped-italian",
   "metadata": {},
   "source": [
    "### 3.1 定义一个卷积"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "favorite-reggae",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv = torch.nn.Conv2d(1, 40, 3, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caroline-vector",
   "metadata": {},
   "source": [
    "### 3.2 定义输入 a 并且输出指定范围数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "natural-grace",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.7617,  0.7561, -0.7430, -0.0470, -0.3359])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.randn((64, 1, 28, 28))\n",
    "a[0][0][0][:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "referenced-lecture",
   "metadata": {},
   "source": [
    "### 3.3 卷积运算并且输出指定范围数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "consistent-brunei",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.3136,  0.5206, -0.1667, -0.5224,  0.4417], grad_fn=<SliceBackward>)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_out = conv(a)\n",
    "a_out[0][0][0][:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "marked-consumption",
   "metadata": {},
   "source": [
    "### 3.4 定义量化卷积层"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "seventh-petersburg",
   "metadata": {},
   "outputs": [],
   "source": [
    "qconv1 = QConv2d(conv, has_qin=True, has_qout=True, num_bits=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rising-persian",
   "metadata": {},
   "source": [
    "### 3.5 计算S 和 z，进行中间参数的量化，并保存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "accepting-flight",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = qconv1(a)\n",
    "qconv1.freeze()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "severe-necklace",
   "metadata": {},
   "source": [
    "### 3.6 量化输入"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "pleasant-coffee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "量化输入，展示部分数据：tensor([ 97., 144.,  98., 119., 110.])\n",
      "\n",
      "反量化输入，展示部分数据：\n",
      "\n",
      "tensor([-0.7770,  0.7446, -0.7446, -0.0648, -0.3561])\n",
      "\n",
      "原始数据对比：\n",
      "\n",
      "tensor([-0.7617,  0.7561, -0.7430, -0.0470, -0.3359])\n"
     ]
    }
   ],
   "source": [
    "# 量化输入\n",
    "qa = qconv1.q_in.quantize_tensor(a).int().float()\n",
    "print(f\"量化输入，展示部分数据：{qa[0][0][0][:5]}\")\n",
    "\n",
    "# 反量化输入\n",
    "# 这部分没必要，只是为了给你们展示看效果\n",
    "qaa = qconv1.q_in.dequantize_tensor(qa)\n",
    "print(f\"\\n反量化输入，展示部分数据：\\n\\n{qaa[0][0][0][:5]}\\n\")\n",
    "print(f\"原始数据对比：\\n\\n{a[0][0][0][:5]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "toxic-packaging",
   "metadata": {},
   "source": [
    "### 3.7 使用量化输入进行推理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "blind-marina",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "推理输出，展示部分数据：tensor([120., 155., 126., 112., 151.], grad_fn=<SliceBackward>)\n",
      "\n",
      "反量化推理输出，展示部分数据：\n",
      "\n",
      "tensor([-0.3205,  0.5423, -0.1726, -0.5177,  0.4437], grad_fn=<SliceBackward>)\n",
      "\n",
      "原始推理结果对比：\n",
      "\n",
      "tensor([-0.3136,  0.5206, -0.1667, -0.5224,  0.4417], grad_fn=<SliceBackward>)\n"
     ]
    }
   ],
   "source": [
    "qa_out = qconv1.quantize_inference(qa)\n",
    "print(f\"推理输出，展示部分数据：{qa_out[0][0][0][:5]}\")\n",
    "\n",
    "qaa_out = qconv1.q_out.dequantize_tensor(qa_out)\n",
    "print(f\"\\n反量化推理输出，展示部分数据：\\n\\n{qaa_out[0][0][0][:5]}\\n\")\n",
    "print(f\"原始推理结果对比：\\n\\n{a_out[0][0][0][:5]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "appreciated-silver",
   "metadata": {},
   "source": [
    "## 4、无法量化的缘故·教程"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "handed-conducting",
   "metadata": {},
   "source": [
    "### 4.1 定义卷积"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "completed-adolescent",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv = torch.nn.Conv2d(1, 40, 3, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "considered-civilian",
   "metadata": {},
   "source": [
    "### 4.2 定义输入并查看类型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "quick-louis",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: torch.Size([64, 1, 28, 28]) \n",
      "dtype: torch.float32\n"
     ]
    }
   ],
   "source": [
    "a = torch.randn((64, 1, 28, 28))\n",
    "\n",
    "print(f\"shape: {a.shape} \\ndtype: {a.dtype}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "infectious-colors",
   "metadata": {},
   "source": [
    "### 4.3 卷积运算（正常输出）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "absolute-burke",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: torch.Size([64, 40, 26, 26]) \n",
      "dtype: torch.float32\n"
     ]
    }
   ],
   "source": [
    "a_out = conv(a)\n",
    "\n",
    "print(f\"shape: {a_out.shape} \\ndtype: {a_out.dtype}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "likely-coach",
   "metadata": {},
   "source": [
    "### 4.4 改变输入类型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "polished-photographer",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.uint8"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = a.to(torch.uint8)\n",
    "\n",
    "b.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "thermal-christopher",
   "metadata": {},
   "source": [
    "### 4.5 卷积运算（错误输出）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "preceding-bhutan",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "expected scalar type Byte but found Float",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-b9917d34543f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mb_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/envs/20210222_TensorRT官方开源库/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/20210222_TensorRT官方开源库/lib/python3.6/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    422\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 423\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    424\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    425\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/20210222_TensorRT官方开源库/lib/python3.6/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight)\u001b[0m\n\u001b[1;32m    418\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[1;32m    419\u001b[0m         return F.conv2d(input, weight, self.bias, self.stride,\n\u001b[0;32m--> 420\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    422\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: expected scalar type Byte but found Float"
     ]
    }
   ],
   "source": [
    "b_out = conv(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "legislative-remainder",
   "metadata": {},
   "source": [
    "### 4.6 pytorch 目前无法量化的缘故（猜测）\n",
    "- https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html\n",
    "- https://www.tensorflow.org/api_docs/python/tf/nn/conv2d#args\n",
    "\n",
    "for pytorch:\n",
    "> This module supports TensorFloat32.\n",
    "\n",
    "for tensorflow:\n",
    "> A Tensor. Must be one of the following types: half, bfloat16, float32, float64."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "modern-flesh",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "empty-collectible",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cellular-circle",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
